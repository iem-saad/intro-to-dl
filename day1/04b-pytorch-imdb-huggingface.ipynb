{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2edd322b-1e0a-4fc4-919b-e808ad472cfe",
   "metadata": {},
   "source": [
    "# IMDB movie review sentiment classification using Hugging Face models\n",
    "\n",
    "In this notebook, we'll test pre-trained sentiment analysis models and later finetune a DistilBERT model to perform IMDB movie review sentiment classification. This notebook is adapted from [Getting Started with Sentiment Analysis using Python](https://huggingface.co/blog/sentiment-analysis-python)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9243fc9-da3f-470d-9e0f-9aaa9528efcd",
   "metadata": {},
   "source": [
    "Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1227c62-d120-4908-8d35-6bf0f236be50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "from huggingface_hub import notebook_login\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35124c9a-1f07-416b-834d-f9c7508f682c",
   "metadata": {},
   "source": [
    "Check if PyTorch is using the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b124df20-1f8a-4a5e-9975-4798bfdaf0f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch version: 2.4.1+rocm6.1\n",
      "Using GPU, device name: AMD Instinct MI250X\n"
     ]
    }
   ],
   "source": [
    "print('Using PyTorch version:', torch.__version__)\n",
    "if torch.cuda.is_available():\n",
    "    print('Using GPU, device name:', torch.cuda.get_device_name(0))\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    print('No GPU found, using CPU instead.') \n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5800ebf-82bd-4cdc-9067-66ee8480d528",
   "metadata": {},
   "source": [
    "## Use Pre-trained Sentiment Analysis Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c82b0f7-62d8-4e3f-9e99-ef3ebc6522bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7277f837e82442f8dc7fa4b3ab046f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25c3e0f7510e4f0586e07c758a72dab6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b313ac60f06c4fcdaff3b8aad2fb477c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca78615d4cdc4eaeb999544c27e0af69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998656511306763},\n",
       " {'label': 'NEGATIVE', 'score': 0.9991129040718079}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_pipeline = pipeline(\"sentiment-analysis\",device=device)\n",
    "data = [\"I love you\", \"I hate you\"]\n",
    "sentiment_pipeline(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97a94f5-1548-46f2-a2f9-1715113e90ab",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "- This code snippet above utilizes the **[pipeline](https://huggingface.co/docs/transformers/main_classes/pipelines)** class to generate predictions using models from the Hub. It applies the [default sentiment analysis model](https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english) to evaluate the provided list of text data.\n",
    "- The analysis results are **POSITIVE** for first entry and **NEGATIVE** for the second entry."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c273d882-0aa9-4d86-a1fa-fd518e2c3ce0",
   "metadata": {},
   "source": [
    "One can also use a specific sentiment analysis model by providing the name of the model, e.g., if you want a sentiment analysis model for tweets, you can specify the model id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c183b485-adc5-447d-b3b7-bb66e173c80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "emoji is not installed, thus not converting emoticons or emojis into text. Install emoji: pip3 install emoji==0.6.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POS', 'score': 0.9916695356369019},\n",
       " {'label': 'NEG', 'score': 0.9806600213050842}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "specific_model = pipeline(model=\"finiteautomata/bertweet-base-sentiment-analysis\", device = device)\n",
    "specific_model(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf45bd1-3964-4d32-944b-edd0783163bb",
   "metadata": {},
   "source": [
    "## Fine-tuning DistilBERT model using IMDB dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec252bb-b0b0-48dc-8e3a-b65b72f931c1",
   "metadata": {},
   "source": [
    "- The [IMDB](https://huggingface.co/datasets/stanfordnlp/imdb) dataset contains 50000 movies reviews from the Internet Movie Database, split into 25000 reviews for training and 25000 reviews for testing. Half of the reviews are positive and half are negative. \n",
    "\n",
    "- The IMDB dataset is relatively large, so let's use 5000 samples for training to speed up our process for this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48bb7a7d-9194-4904-bc91-bd1adb191ea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db9f1ad1e4614b288d25fd39891ccb0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/21.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b4633ce9e5945aa92e62c62cd9aaac3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/20.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "913f34943df9490ba937914309322004",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/42.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7f911e99d3040c7bf4ed87e94827b96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3e4a9ad61ad4cdfbe2d35557a643747",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32353db4d218448a8ba99db1fc58cd9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating unsupervised split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imdb = load_dataset(\"imdb\")\n",
    "small_train_dataset = imdb[\"train\"].shuffle(seed=0).select([i for i in list(range(5000))])\n",
    "test_dataset = imdb[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fe9183-d554-482c-8f3a-a75096e10e14",
   "metadata": {},
   "source": [
    "To preprocess our data, we will use DistilBERT tokenizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbf1e5fc-3831-47d0-ab3f-01d6dd70482a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "169ad39d894b4d18b97e3fc7df6f35d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce4fc3d6e8ec4cb492b3ead912cf542c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62b70f713fe74a3aa3b465f45d8b1f30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "021ed26454d34f8e8f0ca979b59160ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e45582-a0c3-4a80-8a06-d4ce232a1ead",
   "metadata": {},
   "source": [
    "- Next, we will prepare the text inputs for the model for both splits of our dataset (training and test) by using the map method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ab50bd2-e54b-4e31-a162-24923b763731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d362397101504b92a094121ac53b4170",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "598c0a6fe6c74709b1a366865e2236f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_function(examples):\n",
    "   return tokenizer(examples[\"text\"], truncation=True)\n",
    " \n",
    "tokenized_train = small_train_dataset.map(preprocess_function, batched=True)\n",
    "tokenized_test = test_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b9b4c0-9aea-481b-bb26-5f9bd18228c1",
   "metadata": {},
   "source": [
    "- To speed up training, let's use a data_collator to convert your training samples to PyTorch tensors and concatenate them with the correct amount of padding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f10d80c5-77c3-43a6-a7d9-47d97deef882",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0455d055-7b18-47a2-b983-e7a35e46398f",
   "metadata": {},
   "source": [
    "### Training the model\n",
    "- We will be throwing away the pretraining head of the DistilBERT model and replacing it with a classification head fine-tuned for sentiment analysis. This enables us to transfer the knowledge from DistilBERT to our custom model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1644ded6-7d6a-43d2-b303-3d43eb316e4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af8a890eb17644048375ad741d1902e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6577793-6f3d-48a3-b13e-95116be72685",
   "metadata": {},
   "source": [
    "- Then, let's define the metrics you will be using to evaluate how good is your fine-tuned model (accuracy and f1 score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81da7601-9ca0-45ee-94f8-d9d773fff695",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "   load_accuracy = load_metric(\"accuracy\")\n",
    "   load_f1 = load_metric(\"f1\")\n",
    "  \n",
    "   logits, labels = eval_pred\n",
    "   predictions = np.argmax(logits, axis=-1)\n",
    "   accuracy = load_accuracy.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
    "   f1 = load_f1.compute(predictions=predictions, references=labels)[\"f1\"]\n",
    "   return {\"accuracy\": accuracy, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad53c65b-3463-4707-a8ad-ebd2de387133",
   "metadata": {},
   "source": [
    "- Define the training arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96b56df8-a9ac-41ec-9ad7-86c0e0cec2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_name = \"finetuning-sentiment-model-5000-samples\"\n",
    " \n",
    "training_args = TrainingArguments(\n",
    "   output_dir=repo_name,\n",
    "   learning_rate=2e-5,\n",
    "   per_device_train_batch_size=16,\n",
    "   per_device_eval_batch_size=16,\n",
    "   num_train_epochs=10,\n",
    "   weight_decay=0.01,\n",
    "   save_strategy=\"epoch\",\n",
    "   push_to_hub=False,\n",
    ")\n",
    " \n",
    "trainer = Trainer(\n",
    "   model=model,\n",
    "   args=training_args,\n",
    "   train_dataset=tokenized_train,\n",
    "   eval_dataset=tokenized_test,\n",
    "   tokenizer=tokenizer,\n",
    "   data_collator=data_collator,\n",
    "   compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaad4946-5446-4cd1-ae2f-8502d2e3037f",
   "metadata": {},
   "source": [
    "- Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e53f771c-d1fb-4a5b-a426-ae5bd53964df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3130' max='3130' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3130/3130 07:28, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.128900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.080600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.023400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.016800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.003600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.002100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3130, training_loss=0.041074030658307545, metrics={'train_runtime': 447.4617, 'train_samples_per_second': 111.741, 'train_steps_per_second': 6.995, 'total_flos': 6541136655478080.0, 'train_loss': 0.041074030658307545, 'epoch': 10.0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3eee23-b26c-4687-8d27-7d075d76d3a9",
   "metadata": {},
   "source": [
    "- Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a951518-0ee7-4e73-b47b-f679b7e6e628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1563' max='1563' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1563/1563 01:13]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.6160064339637756,\n",
       " 'eval_accuracy': 0.90988,\n",
       " 'eval_f1': 0.9106909263883934,\n",
       " 'eval_runtime': 74.5624,\n",
       " 'eval_samples_per_second': 335.29,\n",
       " 'eval_steps_per_second': 20.962,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61722a1b-3347-469c-b0d9-89398e4601ca",
   "metadata": {},
   "source": [
    "- Model inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3db7322-4f03-4fd2-996b-948e3c271da4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_1', 'score': 0.999527096748352},\n",
       " {'label': 'LABEL_0', 'score': 0.9998001456260681}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = pipeline(\"text-classification\", model=model,tokenizer=tokenizer, device = device)\n",
    "pipe([\"I love this move\", \"This movie sucks!\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8eb61e-a673-4b22-8c6d-7262946964f6",
   "metadata": {},
   "source": [
    "## Task Compare the test dataset accuracy achieved from finetuned DistilBERT model and the previous RNN model. What do you notice?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db67c62-d0ea-4842-84ca-831fd9f86187",
   "metadata": {},
   "source": [
    "In my experiment with sentiment analysis on the IMDB dataset, I tested three different models: a Simple RNN, a GRU-based RNN, and a fine-tuned DistilBERT model. Here’s a breakdown of each model’s performance and my observations.\n",
    "\n",
    "  **Model Performance Summary**\n",
    "\n",
    "  \n",
    "\n",
    "1. **Model 1: Simple RNN**\n",
    "-  **Architecture**: This model uses a single-layer LSTM with 32 hidden units, a dropout layer for regularization, and a sigmoid activation for binary classification.\n",
    "\n",
    "-  **Test Accuracy**: 77.4%\n",
    "\n",
    "-  **Test Loss**: 0.5666\n",
    "\n",
    "-  **Observation**: The Simple RNN had decent performance, but it showed signs of overfitting. Despite applying dropout, the model’s test accuracy evened out, and the gap between training and test accuracy suggested it wasn’t generalizing well to new data.\n",
    "\n",
    "2. **Model 2: GRU-based RNN**\n",
    "\n",
    "-  **Architecture**: This model is a more complex two-layer bidirectional GRU with additional dropout layers to help combat overfitting.\n",
    "\n",
    "-  **Test Accuracy**: 78.0%\n",
    "\n",
    "-  **Test Loss**: 0.9487\n",
    "\n",
    "-  **Observation**: The GRU-based model provided a slight accuracy improvement over the Simple RNN, likely due to the bidirectional structure and additional layer, allowing it to capture both forward and backward context. However, like the Simple RNN, it also struggled with overfitting, and the improvements in accuracy and loss were minor. This indicated that adding complexity in RNN architecture did not significantly impact generalization.\n",
    "\n",
    "3. **Model 3: Fine-tuned DistilBERT**\n",
    "\n",
    "-  **Architecture**: The DistilBERT model, pretrained on a large corpus and fine-tuned on the IMDB dataset, utilizes transformers and attention mechanisms to capture complex relationships in text.\n",
    "\n",
    "-  **Test Accuracy**: 90.98%\n",
    "\n",
    "-  **Test Loss**: 0.6160\n",
    "\n",
    "-  **Observation**: DistilBERT outperformed both RNN-based models by a large margin, achieving an accuracy of 90.98%. Unlike the RNNs, DistilBERT did not show signs of overfitting and was able to generalize well to the test data. The transformer-based architecture, with its attention mechanism, allowed it to capture nuanced patterns in the text that the RNNs struggled with, especially on longer sequences.\n",
    "  \n",
    "\n",
    "**Key Takeaways**\n",
    " \n",
    "\n",
    "1. **Overfitting in RNNs**: Both the Simple RNN and GRU models showed signs of overfitting, as their test accuracy didn’t improve significantly despite adding layers and dropout. This suggests that RNNs may struggle to generalize on complex text data without extensive regularization or larger datasets.\n",
    "\n",
    "2. **Effectiveness of Transformers**: DistilBERT, as a pretrained model, demonstrated a clear advantage. It benefited from large-scale pretraining, which allowed it to start with a better understanding of language structure, whereas the RNNs had to learn from scratch on the IMDB dataset alone. Fine-tuning this model allowed it to adapt to sentiment-specific nuances in the data, leading to superior performance.\n",
    "\n",
    "3. **Concluding Observation**: From this experiment, I noticed that pretrained transformer models like DistilBERT are more effective for text classification tasks than RNNs, especially when overfitting is an issue. This result shows that leveraging pretrained language models can lead to substantial improvements in both accuracy and generalization, making transformers the preferred choice for handling nuanced NLP tasks like sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e37cd4-b193-4f52-a85c-9b692fd5f87a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
