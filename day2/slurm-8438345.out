The following modules were not unloaded:
  (Use "module --force purge" to unload all):

  1) ModuleLabel/label   2) lumi-tools/24.05   3) init-lumi/0.2

The following sticky modules could not be reloaded:

  1) lumi-tools
NOTE: This module uses Singularity. Some commands execute inside the container
(e.g. python3, pip3).

This module has been installed by CSC.

Documentation: https://docs.csc.fi/apps/pytorch/
Support: https://docs.csc.fi/support/contact/

python3 $*
+ python3 pytorch_dvc_vit.py
Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.
Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:
- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([1]) in the model instantiated
- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([1, 768]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Using PyTorch version: 2.4.1+rocm6.1 Transformers version: 4.44.2 Device: cuda
TensorBoard log directory: /pfs/lustrep1/users/sabdulla/PDL-2024-11/intro-to-dl/day2/logs/dvc-vit-2024-11-13_11-27-30
Train: Found 2000 images belonging to 2 classes
Validation: Found 1000 images belonging to 2 classes
Test: Found 22000 images belonging to 2 classes
ViTForImageClassification(
  (vit): ViTModel(
    (embeddings): ViTEmbeddings(
      (patch_embeddings): ViTPatchEmbeddings(
        (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))
      )
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (encoder): ViTEncoder(
      (layer): ModuleList(
        (0-11): 12 x ViTLayer(
          (attention): ViTSdpaAttention(
            (attention): ViTSdpaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
            (output): ViTSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (intermediate): ViTIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): ViTOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        )
      )
    )
    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
  )
  (classifier): Linear(in_features=768, out_features=1, bias=True)
)
Epoch 1: train loss: 0.290283 train accuracy: 93.40%, val accuracy: 98.90%
Epoch 2: train loss: 0.043205 train accuracy: 99.85%, val accuracy: 98.90%
Epoch 3: train loss: 0.014037 train accuracy: 100.00%, val accuracy: 99.00%
Epoch 4: train loss: 0.006927 train accuracy: 100.00%, val accuracy: 99.10%
Epoch 5: train loss: 0.004184 train accuracy: 100.00%, val accuracy: 99.10%
Epoch 6: train loss: 0.002819 train accuracy: 100.00%, val accuracy: 99.10%
Epoch 7: train loss: 0.002038 train accuracy: 100.00%, val accuracy: 99.20%
Epoch 8: train loss: 0.001554 train accuracy: 100.00%, val accuracy: 99.20%
Epoch 9: train loss: 0.001232 train accuracy: 100.00%, val accuracy: 99.20%
Epoch 10: train loss: 0.001001 train accuracy: 100.00%, val accuracy: 99.10%
Total training time: 0:03:48.198490.

Testing: accuracy: 99.34%
