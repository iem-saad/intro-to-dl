{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0e6e42c-a2a3-4ba9-be85-056035147486",
   "metadata": {},
   "source": [
    "# IMDB movie review text generation\n",
    "\n",
    "Once you have fine-tuned your model you can test it interactively with this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa458fec-a1e9-4960-9a9f-c7f21d0a7b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "#path_to_model = \"/scratch/project_462000699/data/users/sabdulla/gpt-imdb-model/checkpoint-5000/\"\n",
    "path_to_model = \"/scratch/project_462000699/data/users/mvsjober/gpt-imdb-model/checkpoint-65000/\"\n",
    "generator = pipeline(\"text-generation\", model=path_to_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a5ecc40-1c1d-4c9d-a41c-937bbbbaf025",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_output(output):\n",
    "    for item in output:\n",
    "        text = item['generated_text']\n",
    "        text = text.replace(\"<br />\", \"\\n\")\n",
    "        print('-', text)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf677501-f93d-46b1-a618-0fb792cd44cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = generator(\"This movie was\")\n",
    "print_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fb8536-887f-4fad-a0b3-190d1749a594",
   "metadata": {},
   "source": [
    "## Experiment with the generation strategy\n",
    "\n",
    "You can play with the text generation if you wish. Text generation strategies are discussed here: https://huggingface.co/docs/transformers/generation_strategies\n",
    "\n",
    "Note that we are here using the easy-to-use `TextGenerationPipeline` and its `generator()` function, but the link discusses the `model.generate()` method. The same parameters can be used, though, the pipeline just takes care of some of the pre- and post-processing.\n",
    "\n",
    "In particular these parameters of the `generator()` function might be interesting:\n",
    "\n",
    "- `max_new_tokens`: the maximum number of tokens to generate\n",
    "- `num_beams`: activate Beam search by setting this > 1\n",
    "- `do_sample`: activate multinomial sampling if set to True\n",
    "- `num_return_sequences`: the number of candidate sentences to return (available only for beam search and sampling)\n",
    "\n",
    "Here is a nice blog post explaining in more detail about the different generation strategies: https://huggingface.co/blog/how-to-generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6816b3f3-9a0f-4ca8-a7d9-d7962b0207fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- This movie was awful because the script had so much potential as it did. The story is so good and it should go a long way for the cast. And because of that, the best acting and cinematography were done with a strong chemistry. The acting were excellent. The lead character is still fresh-faced and looks the whole world. The action is absolutely amazing.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output = generator(\"This movie was awful because\", num_return_sequences=1, max_new_tokens=100, do_sample=True)\n",
    "print_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d478087-fad9-4239-8bdc-83d9b5acedb1",
   "metadata": {},
   "source": [
    "Its not performing good, but i guess with more training we can achieve something really nice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd58b20f-bd8c-4516-974f-62d8e31eb662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- interstellar is greatest movie of all time because it's good not to waste your time with baddies. Don't get me wrong I love this film, the only redeeming characters is that they are real. All the dialogue is a little boring in my opinion. The characters are only an embarrassment in my opinion, but they are great. Not a \"nice\" person, not such a movie of a bad guy. It's good for your friends and kids.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output = generator(\"interstellar is greatest movie of all time because\", num_return_sequences=1, max_new_tokens=100, do_sample=True)\n",
    "print_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df008ff8-cb03-488f-b643-4aa2314de52c",
   "metadata": {},
   "source": [
    "## Compare with the original model without fine-tuning\n",
    "\n",
    "We can also load the original `distilgpt2` model and see how it would have worked without fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ba1f550-970e-419a-aaff-d4e821bacc87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1c05f573ec34cdbb72bab8d7cbc0d40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/762 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2529c3e2657a4d80b1386f64f795d6fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/353M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19335b0c94a84974be44cd7d1122a228",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "972086b5dc9d4ee492af1aa49f9d1968",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36a1faad431d4764a731a90cf07f3bb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3643f8741f814ec48ba37661fd7541b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bff4e7fda2e141c5bcfa2bf5242868f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "generator_orig = pipeline(\"text-generation\", model='distilgpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4995c393-29ad-4df1-b01a-83cd85008297",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- This movie was awful because it did not have a great plot for this sequel.\n",
      "At first it was pretty disappointing that I had to play a character in this second movie as I did not think that it really made sense. I thought that in my last film I loved it and that after the movie I was forced to give two more minutes of dialogue to another character's character because there was really no plot to make the movie great.\n",
      "So what do you think about the screenplay for the sequel of the original? Do you\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output = generator_orig(\"This movie was awful because\", num_return_sequences=1, max_new_tokens=100, do_sample=True)\n",
    "print_output(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fd41308-6980-4bc7-809d-e79135ec2e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- interstellar is greatest movie of all time because of all its twists and turns. There are no exceptions, and in this case, an entire cast of actors have never really played it as a play it is, which has been a huge success in the past few years with a wide variety of character-types, storylines and characters. There are always moments, but no one really deserves to be told the story of that day.\n",
      "\n",
      "On the other hand, I wouldn't be surprised if I saw a great adaptation for \"The Shining\" for\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output = generator_orig(\"interstellar is greatest movie of all time because\", num_return_sequences=1, max_new_tokens=100, do_sample=True)\n",
    "print_output(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cf5565-0d8b-42ba-bdf8-f93a370a872a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
